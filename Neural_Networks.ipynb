{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lUKth-VVKV6K",
        "outputId": "030f19b7-9a90-4758-b66d-10f4d39422f4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset Overview:\n",
            "\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 20000 entries, 0 to 19999\n",
            "Data columns (total 17 columns):\n",
            " #   Column  Non-Null Count  Dtype \n",
            "---  ------  --------------  ----- \n",
            " 0   letter  20000 non-null  object\n",
            " 1   xbox    20000 non-null  int64 \n",
            " 2   ybox    20000 non-null  int64 \n",
            " 3   width   20000 non-null  int64 \n",
            " 4   height  20000 non-null  int64 \n",
            " 5   onpix   20000 non-null  int64 \n",
            " 6   xbar    20000 non-null  int64 \n",
            " 7   ybar    20000 non-null  int64 \n",
            " 8   x2bar   20000 non-null  int64 \n",
            " 9   y2bar   20000 non-null  int64 \n",
            " 10  xybar   20000 non-null  int64 \n",
            " 11  x2ybar  20000 non-null  int64 \n",
            " 12  xy2bar  20000 non-null  int64 \n",
            " 13  xedge   20000 non-null  int64 \n",
            " 14  xedgey  20000 non-null  int64 \n",
            " 15  yedge   20000 non-null  int64 \n",
            " 16  yedgex  20000 non-null  int64 \n",
            "dtypes: int64(16), object(1)\n",
            "memory usage: 2.6+ MB\n",
            "None\n",
            "\n",
            "Summary Statistics:\n",
            "                xbox          ybox         width       height         onpix  \\\n",
            "count  20000.000000  20000.000000  20000.000000  20000.00000  20000.000000   \n",
            "mean       4.023550      7.035500      5.121850      5.37245      3.505850   \n",
            "std        1.913212      3.304555      2.014573      2.26139      2.190458   \n",
            "min        0.000000      0.000000      0.000000      0.00000      0.000000   \n",
            "25%        3.000000      5.000000      4.000000      4.00000      2.000000   \n",
            "50%        4.000000      7.000000      5.000000      6.00000      3.000000   \n",
            "75%        5.000000      9.000000      6.000000      7.00000      5.000000   \n",
            "max       15.000000     15.000000     15.000000     15.00000     15.000000   \n",
            "\n",
            "               xbar          ybar         x2bar         y2bar         xybar  \\\n",
            "count  20000.000000  20000.000000  20000.000000  20000.000000  20000.000000   \n",
            "mean       6.897600      7.500450      4.628600      5.178650      8.282050   \n",
            "std        2.026035      2.325354      2.699968      2.380823      2.488475   \n",
            "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
            "25%        6.000000      6.000000      3.000000      4.000000      7.000000   \n",
            "50%        7.000000      7.000000      4.000000      5.000000      8.000000   \n",
            "75%        8.000000      9.000000      6.000000      7.000000     10.000000   \n",
            "max       15.000000     15.000000     15.000000     15.000000     15.000000   \n",
            "\n",
            "            x2ybar        xy2bar         xedge        xedgey         yedge  \\\n",
            "count  20000.00000  20000.000000  20000.000000  20000.000000  20000.000000   \n",
            "mean       6.45400      7.929000      3.046100      8.338850      3.691750   \n",
            "std        2.63107      2.080619      2.332541      1.546722      2.567073   \n",
            "min        0.00000      0.000000      0.000000      0.000000      0.000000   \n",
            "25%        5.00000      7.000000      1.000000      8.000000      2.000000   \n",
            "50%        6.00000      8.000000      3.000000      8.000000      3.000000   \n",
            "75%        8.00000      9.000000      4.000000      9.000000      5.000000   \n",
            "max       15.00000     15.000000     15.000000     15.000000     15.000000   \n",
            "\n",
            "            yedgex  \n",
            "count  20000.00000  \n",
            "mean       7.80120  \n",
            "std        1.61747  \n",
            "min        0.00000  \n",
            "25%        7.00000  \n",
            "50%        8.00000  \n",
            "75%        9.00000  \n",
            "max       15.00000  \n",
            "\n",
            "Checking for Missing Values:\n",
            " letter    0\n",
            "xbox      0\n",
            "ybox      0\n",
            "width     0\n",
            "height    0\n",
            "onpix     0\n",
            "xbar      0\n",
            "ybar      0\n",
            "x2bar     0\n",
            "y2bar     0\n",
            "xybar     0\n",
            "x2ybar    0\n",
            "xy2bar    0\n",
            "xedge     0\n",
            "xedgey    0\n",
            "yedge     0\n",
            "yedgex    0\n",
            "dtype: int64\n",
            "Epoch 1/20\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.3589 - loss: 1.8925 - val_accuracy: 0.4961 - val_loss: 1.3217\n",
            "Epoch 2/20\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.5209 - loss: 1.2501 - val_accuracy: 0.5525 - val_loss: 1.1713\n",
            "Epoch 3/20\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.5576 - loss: 1.1365 - val_accuracy: 0.5793 - val_loss: 1.0957\n",
            "Epoch 4/20\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5936 - loss: 1.0640 - val_accuracy: 0.6007 - val_loss: 1.0407\n",
            "Epoch 5/20\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6122 - loss: 1.0017 - val_accuracy: 0.6132 - val_loss: 1.0001\n",
            "Epoch 6/20\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6292 - loss: 0.9524 - val_accuracy: 0.6239 - val_loss: 0.9797\n",
            "Epoch 7/20\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.6346 - loss: 0.9356 - val_accuracy: 0.6314 - val_loss: 0.9487\n",
            "Epoch 8/20\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.6445 - loss: 0.8976 - val_accuracy: 0.6454 - val_loss: 0.9367\n",
            "Epoch 9/20\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6668 - loss: 0.8524 - val_accuracy: 0.6436 - val_loss: 0.9181\n",
            "Epoch 10/20\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.6685 - loss: 0.8448 - val_accuracy: 0.6486 - val_loss: 0.9114\n",
            "Epoch 11/20\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6753 - loss: 0.8309 - val_accuracy: 0.6593 - val_loss: 0.8947\n",
            "Epoch 12/20\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6840 - loss: 0.7978 - val_accuracy: 0.6482 - val_loss: 0.8932\n",
            "Epoch 13/20\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6846 - loss: 0.8005 - val_accuracy: 0.6582 - val_loss: 0.8805\n",
            "Epoch 14/20\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6947 - loss: 0.7689 - val_accuracy: 0.6554 - val_loss: 0.8712\n",
            "Epoch 15/20\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6915 - loss: 0.7790 - val_accuracy: 0.6589 - val_loss: 0.8711\n",
            "Epoch 16/20\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7034 - loss: 0.7574 - val_accuracy: 0.6721 - val_loss: 0.8679\n",
            "Epoch 17/20\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7004 - loss: 0.7492 - val_accuracy: 0.6718 - val_loss: 0.8516\n",
            "Epoch 18/20\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7056 - loss: 0.7471 - val_accuracy: 0.6693 - val_loss: 0.8547\n",
            "Epoch 19/20\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7051 - loss: 0.7360 - val_accuracy: 0.6743 - val_loss: 0.8441\n",
            "Epoch 20/20\n",
            "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7033 - loss: 0.7422 - val_accuracy: 0.6646 - val_loss: 0.8533\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
            "\n",
            "Class Distribution:\n",
            " 0        2\n",
            "1       17\n",
            "2       30\n",
            "3      130\n",
            "4      478\n",
            "5      992\n",
            "6     1827\n",
            "7     3472\n",
            "8     8047\n",
            "9     2358\n",
            "10    1578\n",
            "11     868\n",
            "12     137\n",
            "13      49\n",
            "14      13\n",
            "15       2\n",
            "dtype: int64\n",
            "\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00         1\n",
            "           1       0.40      0.33      0.36         6\n",
            "           2       0.20      0.10      0.13        10\n",
            "           3       0.39      0.23      0.29        40\n",
            "           4       0.57      0.56      0.57       147\n",
            "           5       0.50      0.53      0.51       282\n",
            "           6       0.56      0.50      0.53       523\n",
            "           7       0.57      0.67      0.62      1051\n",
            "           8       0.82      0.77      0.80      2432\n",
            "           9       0.52      0.63      0.57       713\n",
            "          10       0.56      0.39      0.46       462\n",
            "          11       0.58      0.71      0.64       269\n",
            "          12       0.46      0.12      0.19        49\n",
            "          13       0.25      0.09      0.13        11\n",
            "          14       0.00      0.00      0.00         4\n",
            "\n",
            "    accuracy                           0.65      6000\n",
            "   macro avg       0.43      0.38      0.39      6000\n",
            "weighted avg       0.66      0.65      0.65      6000\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import optimizers\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from sklearn.preprocessing import OneHotEncoder # Import OneHotEncoder\n",
        "import warnings\n",
        "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
        "\n",
        "# Load the dataset\n",
        "df = pd.read_csv('https://raw.githubusercontent.com/Asad-Shaikh786/Data-Science/refs/heads/main/Alphabets_data.csv')\n",
        "\n",
        "# Data Exploration\n",
        "print(\"Dataset Overview:\\n\")\n",
        "print(df.info())\n",
        "print(\"\\nSummary Statistics:\\n\", df.describe())\n",
        "print(\"\\nChecking for Missing Values:\\n\", df.isnull().sum())\n",
        "\n",
        "# Data Preprocessing\n",
        "# Assuming the last column is the target\n",
        "y = df.iloc[:, -1]\n",
        "X = df.iloc[:, :-1]\n",
        "\n",
        "# --- Changes here ---\n",
        "# Create a OneHotEncoder object\n",
        "encoder = OneHotEncoder(sparse_output=False, handle_unknown='ignore') # sparse=False for dense output\n",
        "\n",
        "# Fit and transform the categorical features in X\n",
        "X_encoded = encoder.fit_transform(X[['letter']]) # Assuming 'letter' is the categorical column\n",
        "\n",
        "# Create a DataFrame from the encoded features\n",
        "X_encoded_df = pd.DataFrame(X_encoded, columns=encoder.get_feature_names_out(['letter']))\n",
        "\n",
        "# Drop the original 'letter' column and concatenate the encoded features\n",
        "X = X.drop('letter', axis=1)\n",
        "X = pd.concat([X, X_encoded_df], axis=1)\n",
        "# --- End of changes ---\n",
        "\n",
        "\n",
        "# Encode categorical target labels\n",
        "y = pd.get_dummies(y)\n",
        "\n",
        "# Normalize feature data\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Basic ANN Model\n",
        "def create_model():\n",
        "    model = keras.models.Sequential([\n",
        "        layers.Input(shape=(X_train.shape[1],)),\n",
        "        layers.Dense(64, activation='relu'),\n",
        "        layers.Dense(32, activation='relu'),\n",
        "        layers.Dense(y_train.shape[1], activation='softmax')\n",
        "    ])\n",
        "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# Train the model\n",
        "model = create_model()\n",
        "history = model.fit(X_train, y_train, epochs=20, batch_size=32, validation_split=0.2)\n",
        "\n",
        "# Evaluate the model\n",
        "y_pred = np.argmax(model.predict(X_test), axis=1)\n",
        "y_test_labels = np.argmax(y_test.values, axis=1)\n",
        "\n",
        "# Class Distribution Check\n",
        "print(\"\\nClass Distribution:\\n\", y.sum())\n",
        "\n",
        "# Updated Evaluation Step\n",
        "print(\"\\nClassification Report:\\n\",\n",
        "      classification_report(y_test_labels, y_pred, zero_division=0))"
      ]
    }
  ]
}